"""
å¯¹è¯ç®¡ç†å™¨ - æ”¯æŒå¤šè½®å¯¹è¯å’ŒAPIè°ƒç”¨æŒä¹…åŒ–è®°å½•
"""

import os
import json
import time
from datetime import datetime
from typing import TYPE_CHECKING, Any, Dict, List, Optional
from pathlib import Path
import yaml
from openai import OpenAI

if TYPE_CHECKING:  # pragma: no cover - used for type hints only
    from .settings import Settings


class ConversationManager:
    """ç®¡ç†å¤šè½®å¯¹è¯å’ŒAPIè°ƒç”¨è®°å½•"""

    def __init__(
        self,
        config_path: str = "config/system_prompts.yaml",
        *,
        settings: Optional["Settings"] = None,
        secrets_path: str = "config/secrets.yaml",
    ):
        if settings is not None:
            self.config = settings.prompts
            self._secrets = settings.secrets
        else:
            self.config = self._load_config(config_path)
            self._secrets = self._load_yaml_file(secrets_path)
        self.messages: List[Dict[str, str]] = []
        self.client: Optional[OpenAI] = None
        self._service_config = {}
        self._default_model = "kimi-k2-0905-preview"

        if isinstance(self._secrets, dict):
            kimi_config = self._secrets.get("services", {}).get("kimi", {})
            if isinstance(kimi_config, dict):
                self._service_config = kimi_config
                self._default_model = kimi_config.get("model", self._default_model)

        # è®¾ç½®æŒä¹…åŒ–ç›®å½•
        self.log_dir = Path("api_logs")
        self.log_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        self._init_api_client()

    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        data = self._load_yaml_file(config_path)
        if data:
            return data
        return self._get_default_config()

    def _load_yaml_file(self, path: str) -> Dict[str, Any]:
        try:
            with open(path, 'r', encoding='utf-8') as f:
                loaded = yaml.safe_load(f) or {}
                return loaded if isinstance(loaded, dict) else {}
        except FileNotFoundError:
            return {}
        except Exception as e:
            print(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return {}

    def _get_default_config(self) -> Dict[str, Any]:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "vasp_orchestrator_prompt": "ä½ æ˜¯VASP-HPCç¼–æ’å™¨åŠ©æ‰‹ã€‚",
            "vasp_analysis_prompt": "è¯·è§£æVASPè®¡ç®—éœ€æ±‚ã€‚",
            "conversation": {
                "max_history_messages": 20,
                "save_interval": 1,
                "context_window": 4096
            },
            "persistence": {
                "enable_logging": True,
                "log_directory": "api_logs",
                "save_format": "json",
                "include_metadata": True
            }
        }

    def _init_api_client(self):
        """åˆå§‹åŒ–APIå®¢æˆ·ç«¯"""
        api_key = self._resolve_api_key()
        if not api_key:
            raise ValueError(
                "KIMI API key not configured. Set the KIMI_API_KEY environment "
                "variable or update config/secrets.yaml."
            )

        base_url = self._service_config.get("base_url", "https://api.moonshot.cn/v1")
        client_kwargs = {"api_key": api_key}
        if base_url:
            client_kwargs["base_url"] = base_url

        self.client = OpenAI(**client_kwargs)

    def _resolve_api_key(self) -> Optional[str]:
        env_key = os.getenv("KIMI_API_KEY")
        if env_key:
            return env_key

        if isinstance(self._secrets, dict):
            api_keys = self._secrets.get("api_keys", {})
            if isinstance(api_keys, dict):
                candidate = api_keys.get("kimi") or api_keys.get("KIMI")
                if candidate and "SET_ME" not in candidate:
                    return candidate
        return None

    def make_messages(self, input_text: str, system_prompt: str = None, n: int = None) -> List[Dict[str, str]]:
        """
        æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒå¤šè½®å¯¹è¯

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            n: æœ€å¤§å†å²æ¶ˆæ¯æ•°é‡

        Returns:
            æ„å»ºçš„æ¶ˆæ¯åˆ—è¡¨
        """
        if n is None:
            n = self.config["conversation"]["max_history_messages"]

        if system_prompt is None:
            system_prompt = self.config["vasp_orchestrator_prompt"]

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
        self.messages.append({
            "role": "user",
            "content": input_text,
            "timestamp": datetime.now().isoformat()
        })

        # æ„å»ºæ–°çš„æ¶ˆæ¯åˆ—è¡¨
        new_messages = []

        # æ·»åŠ ç³»ç»Ÿæ¶ˆæ¯
        new_messages.append({
            "role": "system",
            "content": system_prompt
        })

        # å¦‚æœå†å²æ¶ˆæ¯è¶…è¿‡é™åˆ¶ï¼Œåªä¿ç•™æœ€æ–°çš„næ¡
        if len(self.messages) > n:
            self.messages = self.messages[-n:]

        # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆä¸åŒ…å«å†…éƒ¨æ—¶é—´æˆ³ï¼‰
        for msg in self.messages:
            new_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })

        return new_messages

    def chat(
        self,
        input_text: str,
        system_prompt: str = None,
        temperature: float = 0.7,
        model: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        è¿›è¡Œå¤šè½®å¯¹è¯

        Args:
            input_text: ç”¨æˆ·è¾“å…¥
            system_prompt: ç³»ç»Ÿæç¤ºè¯ï¼ˆå¯é€‰ï¼‰
            temperature: æ¸©åº¦å‚æ•°
            model: æ¨¡å‹åç§°

        Returns:
            åŒ…å«å›å¤å’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        if not self.client:
            raise RuntimeError("APIå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        start_time = time.time()

        if model is None:
            model = self._default_model

        # æ„å»ºæ¶ˆæ¯
        messages = self.make_messages(input_text, system_prompt)

        # å‡†å¤‡APIè°ƒç”¨æ—¥å¿—
        api_log = {
            "timestamp": datetime.now().isoformat(),
            "model": model,
            "temperature": temperature,
            "input": input_text,
            "messages_count": len(messages),
            "system_prompt": system_prompt
        }

        try:
            # è°ƒç”¨API
            completion = self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
            )

            # è·å–å›å¤
            assistant_message = completion.choices[0].message
            response_text = assistant_message.content

            # è®°å½•APIä½¿ç”¨ä¿¡æ¯
            usage = completion.usage
            api_log.update({
                "response": response_text,
                "prompt_tokens": usage.prompt_tokens if usage else None,
                "completion_tokens": usage.completion_tokens if usage else None,
                "total_tokens": usage.total_tokens if usage else None,
                "response_time": time.time() - start_time,
                "status": "success"
            })

            # å°†åŠ©æ‰‹å›å¤æ·»åŠ åˆ°å†å²è®°å½•
            self.messages.append({
                "role": "assistant",
                "content": response_text,
                "timestamp": datetime.now().isoformat()
            })

            # ä¿å­˜æ—¥å¿—
            if self.config["persistence"]["enable_logging"]:
                self._save_api_log(api_log)

            return {
                "response": response_text,
                "usage": {
                    "prompt_tokens": usage.prompt_tokens if usage else None,
                    "completion_tokens": usage.completion_tokens if usage else None,
                    "total_tokens": usage.total_tokens if usage else None
                },
                "response_time": api_log["response_time"],
                "status": "success"
            }

        except Exception as e:
            # è®°å½•é”™è¯¯
            api_log.update({
                "error": str(e),
                "response_time": time.time() - start_time,
                "status": "error"
            })

            if self.config["persistence"]["enable_logging"]:
                self._save_api_log(api_log)

            return {
                "error": str(e),
                "response_time": api_log["response_time"],
                "status": "error"
            }

    def _save_api_log(self, log_data: Dict[str, Any]):
        """ä¿å­˜APIè°ƒç”¨æ—¥å¿—"""
        try:
            timestamp = datetime.now()
            log_filename = f"api_calls_{timestamp.strftime('%Y%m%d')}.json"
            log_path = self.log_dir / log_filename

            # è¯»å–ç°æœ‰æ—¥å¿—
            logs = []
            if log_path.exists():
                with open(log_path, 'r', encoding='utf-8') as f:
                    try:
                        logs = json.load(f)
                    except json.JSONDecodeError:
                        logs = []

            # æ·»åŠ æ–°æ—¥å¿—
            logs.append(log_data)

            # ä¿å­˜æ—¥å¿—
            with open(log_path, 'w', encoding='utf-8') as f:
                json.dump(logs, f, ensure_ascii=False, indent=2)

        except Exception as e:
            print(f"ä¿å­˜APIæ—¥å¿—å¤±è´¥: {e}")

    def save_conversation(self, filename: str = None):
        """ä¿å­˜å½“å‰å¯¹è¯å†å²"""
        if filename is None:
            timestamp = datetime.now()
            filename = f"conversation_{timestamp.strftime('%Y%m%d_%H%M%S')}.json"

        conversation_path = self.log_dir / filename

        try:
            with open(conversation_path, 'w', encoding='utf-8') as f:
                json.dump(self.messages, f, ensure_ascii=False, indent=2)
            print(f"å¯¹è¯å·²ä¿å­˜åˆ°: {conversation_path}")
        except Exception as e:
            print(f"ä¿å­˜å¯¹è¯å¤±è´¥: {e}")

    def load_conversation(self, filename: str):
        """åŠ è½½å¯¹è¯å†å²"""
        conversation_path = self.log_dir / filename

        try:
            with open(conversation_path, 'r', encoding='utf-8') as f:
                self.messages = json.load(f)
            print(f"å¯¹è¯å·²ä» {conversation_path} åŠ è½½")
        except Exception as e:
            print(f"åŠ è½½å¯¹è¯å¤±è´¥: {e}")

    def clear_conversation(self):
        """æ¸…ç©ºå¯¹è¯å†å²"""
        self.messages = []
        print("å¯¹è¯å†å²å·²æ¸…ç©º")

    def spawn_child(self, keep_history: bool = False) -> "ConversationManager":
        """Create a lightweight child session sharing the same API client.

        Claude Code often benefits from orchestrating multiple specialised
        sub-agents that should not leak conversation state between each other.
        This helper returns a new :class:`ConversationManager` instance that
        shares the configuration, API client and persistence settings with the
        parent manager while optionally copying the existing message history.

        Args:
            keep_history: Whether to copy the current message history into the
                spawned session. Defaults to ``False`` so each sub-agent starts
                with a clean slate.

        Returns:
            ConversationManager: A ready-to-use manager sharing the same API
            client connection.
        """

        child = ConversationManager.__new__(ConversationManager)
        child.config = self.config
        child.messages = list(self.messages) if keep_history else []
        child.client = self.client
        child.log_dir = self.log_dir
        child._secrets = self._secrets
        child._service_config = self._service_config
        child._default_model = self._default_model
        return child

    def get_conversation_summary(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯æ‘˜è¦"""
        if not self.messages:
            return {"total_messages": 0}

        user_messages = [msg for msg in self.messages if msg["role"] == "user"]
        assistant_messages = [msg for msg in self.messages if msg["role"] == "assistant"]

        return {
            "total_messages": len(self.messages),
            "user_messages": len(user_messages),
            "assistant_messages": len(assistant_messages),
            "first_message_time": self.messages[0].get("timestamp"),
            "last_message_time": self.messages[-1].get("timestamp")
        }

    def get_recent_logs(self, days: int = 1) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘çš„APIè°ƒç”¨æ—¥å¿—"""
        recent_logs = []
        cutoff_time = datetime.now().timestamp() - (days * 24 * 3600)

        # éå†æ—¥å¿—æ–‡ä»¶
        for log_file in self.log_dir.glob("api_calls_*.json"):
            if log_file.stat().st_mtime < cutoff_time:
                continue

            try:
                with open(log_file, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
                    recent_logs.extend(logs)
            except Exception:
                continue

        # æŒ‰æ—¶é—´æ’åº
        recent_logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
        return recent_logs

    def print_api_statistics(self, days: int = 1):
        """æ‰“å°APIä½¿ç”¨ç»Ÿè®¡"""
        logs = self.get_recent_logs(days)

        if not logs:
            print(f"æœ€è¿‘{days}å¤©æ²¡æœ‰APIè°ƒç”¨è®°å½•")
            return

        total_calls = len(logs)
        successful_calls = len([log for log in logs if log.get("status") == "success"])
        failed_calls = total_calls - successful_calls

        total_tokens = sum(log.get("total_tokens", 0) for log in logs if log.get("total_tokens"))
        total_time = sum(log.get("response_time", 0) for log in logs)

        print(f"\nğŸ“Š APIä½¿ç”¨ç»Ÿè®¡ (æœ€è¿‘{days}å¤©):")
        print(f"æ€»è°ƒç”¨æ¬¡æ•°: {total_calls}")
        print(f"æˆåŠŸæ¬¡æ•°: {successful_calls}")
        print(f"å¤±è´¥æ¬¡æ•°: {failed_calls}")
        print(f"æˆåŠŸç‡: {successful_calls/total_calls*100:.1f}%")
        print(f"æ€»Tokenæ•°: {total_tokens:,}")
        print(f"æ€»å“åº”æ—¶é—´: {total_time:.2f}ç§’")
        print(f"å¹³å‡å“åº”æ—¶é—´: {total_time/total_calls:.2f}ç§’")
